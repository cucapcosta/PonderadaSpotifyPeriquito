{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A título de curiosidade, estou incluíndo o modeloperiquitov11.ipynb, pela simples razão que foi impossível rodar aquele código com minhas configurações atuais, mas talvez teria um resultado bem interessante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pnd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando csv e label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "dadosDeTreino = pnd.read_csv('train.csv')\n",
    "dadosDeTreino.dropna(inplace=True)\n",
    "encoder.fit(dadosDeTreino['explicit'])\n",
    "dadosDeTreino['explicit'] = encoder.transform(dadosDeTreino['explicit'])\n",
    "encoder.fit(dadosDeTreino['track_genre'])\n",
    "dadosDeTreino['track_genre'] = encoder.transform(dadosDeTreino['track_genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando correlações entre as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity_target    1.000000\n",
       "danceability         0.057848\n",
       "track_genre          0.054439\n",
       "loudness             0.048140\n",
       "time_signature       0.036454\n",
       "explicit             0.016312\n",
       "tempo                0.012839\n",
       "key                  0.004285\n",
       "liveness            -0.007691\n",
       "acousticness        -0.009095\n",
       "mode                -0.013869\n",
       "energy              -0.025979\n",
       "valence             -0.043138\n",
       "speechiness         -0.091055\n",
       "instrumentalness    -0.100967\n",
       "Name: popularity_target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadosDeTreino[[ 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre', 'popularity_target']].corr()['popularity_target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipóteses\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; A princípio, o instrumentalness é a feature que mais afeta a popularidade, mas de forma negativa. Em muitos casos, as músicas com vocais tendem a ser mais populares por diversas questões, como por exemplo a facilidade de lembrar de uma música pela letra ou a conexão mais profunda com o conteúdo. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; A segunda maior correlação também é inversamente proporcional, e da mesma forma, se refere à presença de palavras faladas na música. Ironicamente, parece que a presença de vocais na música é muito importante, mas quanto menos palavras tiverem melhor.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Por fim, vemos que a nota em que a música está não parece fazer uma diferença significativa na popularidade da música, talvez porque realmente não seja uma coisa que o ouvinte médio consiga até perceber entre uma música e outra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando conjunto de treino\n",
    "#### Mesmo com a análise acima, adicionar todas as colunas como features melhorou o resultado razoavelmente as custas de tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dadosDeTreino[[ 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']]\n",
    "y=dadosDeTreino['popularity_target']\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Para encontrar os parâmetros abaixo de cada modelo, diversos GridSearchCV foram realizados, levando entre 5-13h cada. Não foi divertido. Estarei incluíndo um dos exemplos aqui, mas não recomendo tentar rodá-los. Alguns outros estão perdidos entre um total de 11 arquivos em que foram feitos diversos testes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "grid_parametros = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15, 20, 50, 100],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': [42],\n",
    "}\n",
    "melhorClassificador = GridSearchCV(classifier, grid_parametros, cv=5,scoring='accuracy' ,n_jobs=-1)\n",
    "melhorClassificador.fit(x_treino, y_treino)\n",
    "print('****************************************************************************************')\n",
    "print(melhorClassificador.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n",
      "0.8300751879699249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      4092\n",
      "           1       0.82      0.83      0.83      3888\n",
      "\n",
      "    accuracy                           0.83      7980\n",
      "   macro avg       0.83      0.83      0.83      7980\n",
      "weighted avg       0.83      0.83      0.83      7980\n",
      "\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "modelos_base = [('modelo9', ExtraTreesClassifier(criterion='gini', max_depth=None, max_features=None, n_estimators=1000, n_jobs=-1)),('modelo8', RandomForestClassifier(bootstrap=True, criterion='gini',  max_depth=None, max_features=None, n_estimators=1000, n_jobs=-1, random_state=42)),('modelo2',RandomForestClassifier(bootstrap=True, criterion='gini', max_depth=20, max_features=None, n_estimators=500, n_jobs=-1, random_state=42))]\n",
    "meta_modelo = SVC()\n",
    "modelo_stack = StackingClassifier(estimators=modelos_base, final_estimator=meta_modelo, cv=5)\n",
    "modelo_stack.fit(x_treino, y_treino)\n",
    "print(\"*******************************************************\")\n",
    "print(accuracy_score(y_teste, modelo_stack.predict(x_teste)))\n",
    "print(classification_report(y_teste, modelo_stack.predict(x_teste)))\n",
    "\n",
    "print(\"*******************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pnd.read_csv('test.csv')\n",
    "df.dropna(inplace=True)\n",
    "encoder.fit(df['explicit'])\n",
    "df['explicit'] = encoder.transform(df['explicit'])\n",
    "encoder.fit(df['track_genre'])\n",
    "df['track_genre'] = encoder.transform(df['track_genre'])\n",
    "x=df[[ 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']]\n",
    "df['popularity_target'] = modelo_stack.predict(x)\n",
    "df[['track_unique_id', 'popularity_target']].to_csv('submission7.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
